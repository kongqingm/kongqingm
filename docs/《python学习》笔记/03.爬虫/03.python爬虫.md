---
title: python爬虫
date: 2024-08-26 22:23:47
permalink: /pages/f0e0b3/
categories:
  - 《python学习》笔记
  - 爬虫
tags:
  - python爬虫
---



## 1 爬虫的基本原理

网页请求的过程分为两个环节：

1. Request （请求）：每一个展示在用户面前的网页都必须经过这一步，也就是向服务器发送访问请求。
2. Response（响应）：服务器在接收到用户的请求后，会验证请求的有效性，然后向用户（客户端）发送响应的容，客户端接收服务器响应的内容，将内容展示出来，就是我们所熟悉的网页请求

## 2 关于爬虫的合法性

​        几乎每一个网站都有一个名为 robots.txt 的文档，当然也有部分网站没有设定 robots.txt。对于没有设定 robots.txt 的网站可以通过网络爬虫获取没有口令加密的数据，也就是该网站所有页面数据都可以爬取。如果网站有 robots.txt 文档，就要判断是否有禁止访客获取的数据。

## 3 导入requests包

```python
import requests    
```

## 4 定义url的地址

```python
url = r'https://www.baidu.com/s?ie=utf-8&f=3&rsv_bp=1&rsv_idx=1&tn=baidu&'
```

## 5 定义搜索内容

​		如果不需要搜索可以选择去掉这部分

```python
kw = '疫情'
param = {'wd': kw}
```

##  6 伪装请求头

```python
head = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:84.0) Gecko/20100101 Firefox/84.0'}
```

## 7 定义储存结果的文件名

```python
filename = '疫情.txt' 
```

## 8 发起请求

```python
response = requests.get(url=url, params=param, headers=head)
```

## 9 获取请求结果

```python
response.encoding= "utf-8"
result = response.text
```

## 10 存储文件

​		在存储文件之前可以先进行数据清洗以便后续的使用

```python
with open(filename, 'a', encoding='utf-8') as tem:
    tem.write(result) 
```

## 11 也可以使用BeautifulSoup

```python
import requests        #导入requests包
from bs4 import    BeautifulSoup
url='填入网址'
strhtml=requests.get(url)
soup=BeautifulSoup(strhtml.text,'lxml')
#下面的路径为想要抓取的标签地址根据需要进行修改
data = soup.select("#arc-body > div:nth-child(110) > img")
print(data)
```

## 12 清洗数据

```python
for item in data:
    result={
        'title':item.get_text(),
        'link':item.get('href')
    }
print(result)
```

## 13 绘制饼图

```python
fig = plt.figure()
c = (0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0)
matplotlib.rcParams['font.sans-serif'] = ['SimHei']
plt.pie(b_list, labels=a_list, explode=c, autopct='%1.2f%%')  # 画饼图（数据，数据对应的标签，百分数保留两位小数点）
plt.savefig("rumors/templates/饼图2.jpg")   #存储饼图
```

## 14 擦除画布

```python
plt.clf()
```

## 15 绘制柱状图

```python
plt.bar(a_list, b_list)
plt.savefig("rumors/templates/柱状图2.jpg")  #存储柱状图
```

## 16 绘制词云

```python
# 读取文本
pythonInfo = open('test2.txt', 'r', encoding='utf-8', errors='ignore').read()
# print(pythonInfo)
# 切割
pythonCut = jieba.cut(pythonInfo, cut_all=True)
pythonInfoList = ' '.join(pythonCut)  # 返回一个生成器对象
# print(pythonInfoList)
backgroud = np.array(Image.open('上海.png'))  # 将图片格式化成RBG数组
myCloudword = wordcloud.WordCloud(font_path='simkai.ttf',  # 字体路径
                                  width=1000, height=500,
                                  mask=backgroud,  # 字体颜色
                                  scale=1,  # 比例
                                  max_words=200,  # 最大字数
                                  min_font_size=4,  # 最小字体
                                  stopwords=STOPWORDS,  # 默认停止词
                                  random_state=50,  # 随机角度
                                  background_color='black',  # 背景颜色
                                  max_font_size=500  # 最大字体
                                  ).generate(pythonInfoList)
plt.imshow(myCloudword)
myCloudword.to_file("rumors/templates/词云图片2.jpg")
```